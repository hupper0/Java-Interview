###面向我的介绍 
#### 基本信息
* 姓名：吕鸿鹏；年龄：28， 1991-05；
* 大学：2009-2013 辽工大 一本统招院校。专业： 信息管理，专业以计算机和信息管理为主。
* 工作经历：
	* 1、2013.6毕业-2015.4 在凤凰网工作，在凤凰汽车门户 负责数据分析和数据推荐服务的研发
		* 1、负责门户网站数据分析平台的研发工作，包括数据采集（Python，hdfs）+数据分析(python+hive)+数据展示,分析一些网站指标，对标的是百度统计。
		* 2、数据挖掘工作：主要针对凤凰汽车板块根据汽车特征计算相似汽车；应用的算法欧式距离，把汽车的特征（价格（厂商、建议、最低）、发动机、媒体参数、车轮制动等等参数）转成一个向量，不同车之间计算向量的距离，计算之前要对向量进行缺省值填充、归一化、在计算相似度。计算的结果存入redis,每天定时计算任务。对外提供http服务。
	* 2、2015.4~2016.12 在亚信安全 负责大数据检索服务的研发，hbase集群优化稳定 。
		* 1、针对三类日志进行匹配，大数据联查分析。用户日志，手机号+私网ip ,私网ip(aaa认证系统) +公网ip（dpi日志），还有nat设备日志, 公网ip+url;三种或者俩种业务日志合并，查询。 解决方案：前期：flume+hbase方案， 我负责flume所有的日志采集工作，hbase入库，表设计，服务端提供服务。后期方案：spark+solr检索，我负责对合并后日志进行入solr集群+服务提供。
	* 3、最近俩年在美图，所在部门——[美图云/大数据于AI/算法工程]（主要负责算法平台的开发，包括机器学习平台，调度系统，推荐引擎，属于架构研发方向），负责大数据平台的调度平台(Kunkka)的研发设计研发工作。
		* 1、调度平台负责人，负责调度平台的前期调研、架构设计、设计方案确定、 后期开发、对接需求、第三方sdk开发。核心开发人员，前后有几个实习生，和一个前端进行对接。主要技术:java,netty,vue，内部通信使用的 netty 进行通信
		* 主从架构，解决的事情主要是，多机器多任务的依赖调度。可以失败重试、故障转移、多机依赖、错误超时监控、队列优先级并发数排队、机器排他资源限制、权限划分 防止跨部门任务权限限制。
		* kunkka产品推广：
			* cover住核心业务
			* 保证服务稳定性
			* 产品易用性
			* 完善产品用户手册 
			* 产品宣讲（宣讲可能会分很多期）
			* 拉讨论组————建立意见反馈通道
			* 开始试用————以不是那么核心的业务开始试用
			* 逐步开始扩充本部门更多业务
			* 对外部门推广————流程还要重头再来一遍！！~~！！
		* 2、 mml（meitu machine learnning）系统 核心开发人员，负责其中的一个组件研发工作：系统主要包含了特征工程、机器学习算法、模型评估及相应特征和样本可视化的 平台。主要技术栈:java,mysql,hadoop&hdfs,hive metastore,spark,redis 主要功能包括:数据定义，功能可视化，消息交互，算子实现，调度管理，系统高可用 我负责的部分:部分算子(spark 编写)实现，简易版微服务框架实现，算子热部署等等。

* 工作特点&自我评价：
	* 责任：服务7*24 监控报警
	* 沟通：对接产品，对接测试
	* 有代码洁癖，对代码的书写风格个人有规范，遵守规范，比较喜欢阿里的idea代码检查插件
	* 注重文档：没有好的文档不是好的系统
	* 阅读源码方面：主要集中在jdk集合、多线程、锁、flume（看过其中的sink组件）、hadoop-yarn source里面的demo、netty只看了大概的框架（<a href="https://github.com/hupper0/nioNetty">基于reactor模型实现的</a>）（ps: emmmm  读的不是很多 还在学习中,这部分大部分还是需要问题或者工作驱动)
	* 接触的多的技术:java spring jvm nio netty rpc ,flume hbase hive mr spark 、yarn
	* 比较关注调度方向，包括任务调度、资源调度、
	* 学习中：容器集群、容器编排，弹性扩容，服务亲和 k8s..
	* 历史评级：去年年底美图绩效A 亚信评级p7
	* 其他开发：简易轻量级rpc框架，模仿dubbo; spark和hdfs 任务命令提交客户端
	* github: [https://github.com/hupper0](https://github.com/hupper0)
	* 离职原因：想去杭州，女朋友在杭州， 很想去阿里~~~~


* 系统方面核心点：
	* 1、调度系统
		* 功能分布: 任务多机器依赖调度、可视化、健康
		* 对标产品: azkaban airflow elasticjob ；
		* 高可用部门实现强化 
			* 任务在agent失败了怎么办
			* agent挂了怎么办
			* master挂了怎么办
				* m-s 区别只在于 触发器 
				* kill -9 停止
				* 正常stop停止 
		* 消息可靠传递 握手,cache
		* workflow之间依赖
		* 优先级排队 并发数控制: 队列关联机器，队列关联机器，指定队列，队列控制任务执行数量
		* sdk
		* 监控
			* ui监控
			* 最晚开始时间 最晚结束时间 
			* 短信+邮件+微信
			* 完成通知 
		* 版本：
			* 编辑
			* 提交
			* 发布-下线，发布只读取当前版本的信息
			* 版本切换 
		* 权限
			* 组权限：
				* master,
				* owner: 可以授权和取消授权其他人为该组的master，权限和master一样，只是可以对人员进行ddl
				* reader: 只读
			* 项目权限:
				* master,
				* owner：可以授权和取消授权其他人为该项目的的master
				* reader
			* 全局权限 : all owner
			* 角色：
				* 超级管理员——全局权：可以创建组
				* 管理员：——对应某个组的组权限
				* 开发人员：项目权限，可以创建项目
				* 只读人员：只能查看
		* 核心点：
			* 调度中心HA
			* 执行器HA
			* 弹性扩容缩容
			* 故障转移
			* 路由策略
			* 任务超时控制
			* 事件触发
			* Rolling实时日志
			* 负载均衡
			* 脚本任务
			* 命令行任务
			* 任务依赖
			* 一致性
			* 自定义任务参数
			* 调度线程池
			* 数据加密
			* 邮件报警
			* 推送maven中央仓库 sdk介入
			* 运行报表
			* 全异步
			* 部署包推送下发
			* 任务分片
			* 容器化：提供官方docker镜像，并实时更新推送dockerhub，进一步实现产品开箱即用； （没做======）
			* [关于算法调度的总结文档](https://github.com/hupper0/javaInterview/blob/master/markdown/hadoop1.x%20vs%20%20hadoop2.x%20%20-%3Eyarn-%3E%E4%BC%8F%E7%BE%B2%E8%B0%83%E5%BA%A6-%3E%E8%AE%BE%E8%AE%A1%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F.md)：
				
			* 任务类型：hive,shell
		* yarn任务监控：提交任务前，拿到任务的applicationId,监控1、yarn最长执行时间，2、最长等待执行时间 3、失败重试 4、重试次数

	* mml机器学习平台
		* [对标第四范式](https://www.4paradigm.com/support/help/)做的
		* 数据依赖
		* 平台开发、算子开发
		* 算子主要以spark算子为主，中间结果数据存在hdfs, memostore存储元数据
		* 算子包括：数据获取、数据预处理、特征工程、模型算法、聚类、模型评估、以jar包形式存在
		* 平台:组装算子编排，算子元数据参数配置组装，算子任务调度（实例、日志、监控、触发、权限）--->可以转移到调度平台
		* 执行节点



	
	
	
	
	